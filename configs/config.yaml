# agent info
agent: "c51"

# experiment settings
seed: 42
verbose: True
game: "breakout"
online: False
tuple_data_path: "/home/freshpate/offline_rl_data/minatar/breakout_first_million_buffer" # path to offline data
offline_data_count: 1000000 # how much offline data to load
target_off: False
save_checkpoint: True
save_online_replay: False 
load_checkpoint_path: null
checkpoint_path: "/home/freshpate/offline_rl_data/minatar/results" # main path where to save checkpoints
save_entire_buffer: False # whether to save each indiviual tuple of the buffer
compute_eigs: True # compute the eigenvalues or not
compute_update_norm: False
compute_grad_norm: False
logging_frequency: 100 # save checkpoint at each this every number of states

# training vars
training_steps: 500000

# estimator settings
batch_size: 512
hidden_size: 128

# exploration, q-learning, optimization settings
epsilon: 1
end_epsilon: 0.1
replay_buffer_size: 100000
replay_start_size: 5000
target_update_freq: 1000
gamma: 0.99
optimizer: "sgd"
lr: 0.004
momentum: 0.95
nesterov: True
beta1: 0.9
beta2: 0.99
adam_eps: 0.01  # Should be 0.01/batch_size in code, based on the dist. dqn paper
weight_decay: 0.1

# Categorical DQN hyperparameters
atoms: 51
v_min: -10
v_max: 10